### Машинное обучение

## ML - решает следующую задачу:
# Требуется подогнать заданный набор точек
# с данными под соответствующую функцию
# (отображение входа на выход), которая улавливает
# важные сигналы и игнорирует помехи, а затем
# убедиться, что на новых данных работает хорошо


# Обучение с учителем (supervised learning)
# Обучение без учителя (unsupervised learning)

## ОчУ - моделирует отношение между признаками и метками.
# Такие модели служат для предсказания меток на основе обучающих данных
# маркированных. После построения модели можно использовать ее
# для присвоения меток новым ранее неизвестным данным

# - задачи классификации (метки - дискретные (можно сосчитать): два или более)
# - задачи регрессии (метки/результат: непрерывные величины (чаще всего - действительные числа))


## ОбУ - моделирование признаки без меток. Такие модели служат для выявления структуры
# немаркированных данных

# - задача кластеризации (выделяет отдельные группы данных - кластеры)
# - понижение размерности (поиск более сжатого представления данных)


## Существуют методы частичного обучения (semi-supervised learning)
# Не все данные промаркированы (не у всех есть метки)


## Методы обучение с подкреплением (reinforcement learning)
# Система обучения улучшает свои характеристики на основе взаимодействия
# (обратной связи) со средой. При этом взаимодействии система получает сигналы
# (функции наград), которые несут в себе информацию насколько хорошо/плохо
# система решила задачу (с точки зрения среды). Пока итоговая награда не станет максимальной

import seaborn as sns

iris = sns.load_dataset("iris")

print(iris.head())
print(type(iris))
print(type(iris.values))
print(iris.values.shape)
print(iris.columns)
print(iris.index)

# Строки - отдельные объекты - образцы (sample)
# Столбцы - признаки (features) - соответствуют конкретным наблюдениям
# Матрицы признаков (features matrix) размер [число образцов х число признаков]
# Целевой массив, массив меток (targets) (- то что хотим найти) - одномерный массив [1 х число образцов] -
# данные, которые мы хотим предсказать на основе имеющихся данных
# Зависимые (метка) и независимые переменные (признаки)


## Процесс построения системы машинного обучения:

# 1. Предварительная обработка
# - На вход поступают необработанные данные и метки
# - Происходит выбор признаков, масштабирование признаков
# - Понижение размерности (выбрасывание ненужных - линейно зависимых и тп)
# - Выборка образцов
# - На выход поступает набор данных: обучающий, тестовый

# 2. Обучение
# - Выбор модели
# - Перекрестная проверка
# - Метрики эффективности
# - Оптимизация гиперпараметров. Параметры, которые получаются не из данных, а являются настраиваемыми характеристиками модели

# 3. Оценка и формирование финальной модели

# 4. Прогнозирование (использование модели)


## SciKit-learn

# 1. Выбираем класс модели
# 2. Устанавливаем гиперпараметры модели
# 3. Создаем матрицу признаков и целевой массив
# 4. Обучение модели ( метод fit() )
# 5. Применять модель к новым данным
# - predict() (с учителем)
# - predict() или transform() (без учителя)



### Обучение с учителем: Линейная регрессия

## Простая линейная регрессия

# y = ax + b
# хотим аппроксимировать набор точек этой функцией (где x - признак, а у - метка)

import matplotlib.pyplot as plt
import numpy as np

# I
np.random.seed(1)
x = 10 * np.random.rand(50)

y = 2 * x - 1 + np.random.randn(50)

plt.scatter(x, y)


# II

# 1. Выбираем класс модели
from sklearn.linear_model import LinearRegression

# 2. Устанавливаем гиперпараметры модели
model = LinearRegression(fit_intercept=True) # Если False - будет проходить через (0,0)

# 3. Создаем матрицу признаков и целевой массив
print(x.shape)
print(y.shape)

X = x[:, np.newaxis] # для библиотеки необходимо добавить второе измерение

# 4. Обучение модели fit()
model.fit(X, y)

print(model.coef_[0]) # a
print(model.intercept_) # b

x_ = np.linspace(0, 10, 30)
y_ = model.coef_[0] * x_ + model.intercept_

plt.plot(x_, y_)

# 5. Применять модель к новым данным

xfit = np.linspace(0, 10, 5)
yfit = model.predict(xfit[:, np.newaxis])

plt.scatter(xfit, yfit)


plt.show()
